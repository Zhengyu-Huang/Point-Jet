{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.ndimage\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy import sparse\n",
    "from scipy.linalg import block_diag\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import torch\n",
    "import pickle\n",
    "from functools import partial\n",
    "\n",
    "# from NeuralNet import *\n",
    "from timeit import default_timer\n",
    "\n",
    "from Solver import *\n",
    "import sys\n",
    "sys.path.append('../Utility')\n",
    "import NeuralNet\n",
    "import KalmanInversion \n",
    "from Numerics import interpolate_f2c, gradient_first_f2c\n",
    "# import imp\n",
    "# imp.reload(KalmanInversion )\n",
    "# imp.reload(NeuralNet)\n",
    "# jupyter nbconvert --to script 'Indirect_NN.ipynb'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nx = 384\n",
    "beta = 1.0\n",
    "tau_inv = [0.01, 0.02, 0.04, 0.08, 0.16]\n",
    "N_data = len(tau_inv)\n",
    "\n",
    "data_dirs = [\"../data/beta_1.0_Gamma_1.0_relax_\" + str(tau_inv[i]) + \"/\" for i in range(len(tau_inv))]\n",
    "\n",
    "L = 4*np.pi\n",
    "xx, closure_mean,  q_mean, dq_dx_mean = np.zeros((N_data,Nx)), np.zeros((N_data,Nx)), np.zeros((N_data,Nx)), np.zeros((N_data,Nx))\n",
    "for i in range(N_data):  \n",
    "    closure_mean[i, :], q_mean[i, :], dq_dx_mean[i, :] = load_data(data_dirs[i])\n",
    "    xx[i, :] = np.linspace(-L/2.0, L/2.0, Nx)\n",
    "dx = xx[0, 1] - xx[0, 0]\n",
    "\n",
    "\n",
    "# TODO: clean data\n",
    "omega_jet = np.zeros(Nx)\n",
    "omega_jet[0:Nx//2] = 1.0\n",
    "omega_jet[Nx//2:Nx] = -1.0\n",
    "q_jet = omega_jet + beta*xx[0, :]\n",
    "\n",
    "\n",
    "f = np.zeros(q_mean.shape)\n",
    "\n",
    "chop_l = 50\n",
    "for i in range(N_data):  \n",
    "    q_mean[i, 0:chop_l] = np.linspace(q_jet[0],   q_mean[i,chop_l-1],  chop_l)   #q_jet[0:chop_l]\n",
    "    q_mean[i, -chop_l:] = np.linspace(q_mean[i, -chop_l], q_jet[-1],  chop_l)   #q_jet[-chop_l:]\n",
    "    \n",
    "    \n",
    "    dq_dx_mean[i, 0:chop_l] = np.linspace(beta, dq_dx_mean[i,chop_l-1],  chop_l)\n",
    "    dq_dx_mean[i, -chop_l:] = np.linspace(dq_dx_mean[i, -chop_l], beta, chop_l)\n",
    "    \n",
    "    closure_mean[i, 0:chop_l] = np.linspace(0.0, closure_mean[i,chop_l-1],  chop_l)\n",
    "    closure_mean[i, -chop_l:] = np.linspace(closure_mean[i, -chop_l], 0.0, chop_l)\n",
    "    \n",
    "    f[i, :] = tau_inv[i]*(q_jet - q_mean[i, :])\n",
    "\n",
    "q_mean_abs = np.fabs(q_mean)\n",
    "mu_f = closure_mean/dq_dx_mean\n",
    "# visualize data\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=True, figsize=(12,6))\n",
    "for i in range(N_data):\n",
    "    ax[0].plot(q_mean[i, :], xx[i,:],  \"--\", fillstyle=\"none\", color=\"C\"+str(i))\n",
    "    ax[1].plot(f[i, :], xx[i,:],  \"--\", fillstyle=\"none\", color=\"C\"+str(i))\n",
    "    \n",
    "ax[0].set_xlabel(\"q\")\n",
    "ax[1].set_xlabel(\"f\")   \n",
    "plt.title(\"Training Data\")\n",
    "plt.savefig(\"Point-Jet-Training-Data.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loss : || d(D dq/dx)/dx + f(x)|| on the quadratic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_aug(s_param, params):\n",
    "    \n",
    "    \n",
    "    ind, outd, width   = s_param.ind, s_param.outd, s_param.width\n",
    "    activation, initializer, outputlayer = s_param.activation, s_param.initializer, s_param.outputlayer\n",
    "    \n",
    "    dt, Nt, save_every = s_param.dt,  s_param.Nt,   s_param.save_every\n",
    "    xx, q_jet, tau_inv = s_param.xx, s_param.q_jet, s_param.tau_inv\n",
    " \n",
    "    \n",
    "    N_data, Nx = f.shape\n",
    "    q_sol = np.zeros((N_data, Nx))\n",
    "    \n",
    "    \n",
    "    net =  create_net(ind, outd, layers, width, activation, initializer, outputlayer,  params)\n",
    "    nn_model = partial(nn_flux, net=net, non_negative=True)\n",
    "    model = lambda q, xx, res : nummodel_flux(nn_model, q, xx, res)\n",
    "    \n",
    "    for i in range(N_data):\n",
    "        _, t_data, q_data = explicit_solve(model, q_jet, 1.0/tau_inv[i], dt = dt, Nt = Nt, save_every = save_every, L = L)\n",
    "        q_sol[i, :] = q_data[-1, :]\n",
    "        \n",
    "    return np.hstack((np.reshape(q_sol, -1), params))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start UKI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointJetParam:\n",
    "    def __init__(self, \n",
    "                 xx, q_jet, tau_inv,\n",
    "                 dt, Nt, save_every,\n",
    "                 N_y, ind, outd, layers, width, activation, initializer, outputlayer \n",
    "                 ):\n",
    "        self.theta_names = [\"hyperparameters\"]\n",
    "        \n",
    "        self.ind  = ind\n",
    "        self.outd = outd\n",
    "        self.width = width\n",
    "        self.activation = activation\n",
    "        self.initializer = initializer\n",
    "        self.outputlayer = outputlayer\n",
    "        \n",
    "        self.dt = dt\n",
    "        self.Nt = Nt\n",
    "        self.save_every = save_every\n",
    "\n",
    "        self.xx = xx\n",
    "        self.q_jet  = q_jet\n",
    "        self.tau_inv = tau_inv\n",
    "        \n",
    "        \n",
    "        N_theta = ind*width + (layers - 2)*width**2 + width*outd + (layers - 1)*width + outd\n",
    "        self.N_theta = N_theta\n",
    "        \n",
    "        \n",
    "        self.N_y = N_y + N_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = np.reshape(q_mean, -1)\n",
    "# Sigma_eta = np.fabs(q_mean)\n",
    "# for i in range(N_data):\n",
    "#     Sigma_eta[i, :] = np.mean(Sigma_eta[i, :])\n",
    "# Sigma_eta = np.diag(np.reshape((Sigma_eta*0.01)**2, -1))\n",
    "\n",
    "\n",
    "# N_y = len(y)\n",
    "# ind, outd, width = 2, 1, 10\n",
    "# layers = 2\n",
    "# activation, initializer, outputlayer = \"sigmoid\", \"default\", \"None\"\n",
    "# dt, Nt, save_every = \n",
    "# s_param = PointJetParam(xx, q_jet, dt, Nt, save_every, \n",
    "#                         N_y, ind, outd, layers, width, activation, initializer, outputlayer)\n",
    "\n",
    "\n",
    "# N_theta = s_param.N_theta\n",
    "\n",
    "# theta0_init = NeuralNet.FNN(ind, outd, layers, width, activation, initializer, outputlayer).get_params()\n",
    "\n",
    "# theta0_init = torch.load(\"visc.model\").get_params()\n",
    "\n",
    "# res = loss_aug(s_param, theta0_init)[0:N_y].reshape((N_data,-1))\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=True, figsize=(12,6))\n",
    "# for i in range(4,5):\n",
    "#     ax[0].plot(f[i, :], xx[i,:],  \"--\", fillstyle=\"none\", color=\"C\"+str(i))\n",
    "    \n",
    "#     #ax[0].plot(q_mean[i, :], xx[i,:],  \"--\", fillstyle=\"none\", color=\"C\"+str(i))\n",
    "#     ax[1].plot(-res[i, :], xx[i,1:-1],  \"--\", fillstyle=\"none\", color=\"C\"+str(i))\n",
    "    \n",
    "# ax[0].set_xlabel(\"f\")\n",
    "# ax[1].set_xlabel(\"res\")   \n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.reshape(q_mean, -1)\n",
    "Sigma_eta = np.fabs(q_mean)\n",
    "for i in range(N_data):\n",
    "    Sigma_eta[i, :] = np.mean(Sigma_eta[i, :])\n",
    "Sigma_eta = np.diag(np.reshape((Sigma_eta*0.01)**2, -1))\n",
    "\n",
    "\n",
    "N_y = len(y)\n",
    "ind, outd, width = 2, 1, 10\n",
    "layers = 2\n",
    "activation, initializer, outputlayer = \"sigmoid\", \"default\", \"None\"\n",
    "dt, Nt, save_every = 1.0e-4, 200000, 1000\n",
    "\n",
    "\n",
    "s_param = PointJetParam(xx, q_jet, tau_inv, dt, Nt, save_every, N_y,  ind, outd, layers, width, activation, initializer, outputlayer)\n",
    "N_theta = s_param.N_theta\n",
    "\n",
    "\n",
    "theta0_mean_init = NeuralNet.FNN(ind, outd, layers, width, activation, initializer, outputlayer).get_params()\n",
    "# theta0_init = torch.load(\"visc.model\").get_params()\n",
    "theta0_mean = np.zeros(N_theta)\n",
    "\n",
    "theta0_cov = np.zeros((N_theta, N_theta))\n",
    "np.fill_diagonal(theta0_cov, 100.0**2)  \n",
    "\n",
    "theta0_cov_init = np.zeros((N_theta, N_theta))\n",
    "np.fill_diagonal(theta0_cov_init, 1.0**2)  \n",
    "\n",
    "y_aug = np.hstack((y, theta0_mean))\n",
    "Sigma_eta_aug = block_diag(Sigma_eta, theta0_cov)\n",
    "\n",
    "alpha_reg = 1.0\n",
    "update_freq = 1\n",
    "N_iter = 10\n",
    "gamma = 1.0\n",
    "\n",
    "save_folder = \"indirect_NN\"\n",
    "# uki_obj = KalmanInversion.UKI_Run(s_param, loss_aug, \n",
    "#     theta0_mean, theta0_mean_init, \n",
    "#     theta0_cov,  theta0_cov_init,\n",
    "#     y_aug, Sigma_eta_aug,\n",
    "#     alpha_reg,\n",
    "#     gamma,\n",
    "#     update_freq, \n",
    "#     N_iter,\n",
    "#     save_folder = save_folder)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.3466, -2.5184],\n",
      "        [-0.6371, -1.3686],\n",
      "        [-1.8535, -0.3251],\n",
      "        [ 2.6045,  1.0430],\n",
      "        [-3.9435,  2.4348],\n",
      "        [ 0.7687, -2.6710],\n",
      "        [ 0.7128, -0.8022],\n",
      "        [-4.2854, -1.7867],\n",
      "        [-1.5836,  0.5537],\n",
      "        [-3.3562, -2.3205]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.4804, -0.7656, -0.4958, -3.3868, -0.3848,  0.0622, -2.8766,  2.0415,\n",
      "        -0.4477, -0.0846], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-2.9559, -1.2288,  2.1081,  0.9044,  1.4972,  3.9281, -2.8672, -1.3166,\n",
      "          0.6602,  4.2930]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0272], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#uki_obj = pickle.load( open( save_folder + \"/ukiobj-\" + str(N_iter-1) + \".dat\", \"rb\" ) )\n",
    "uki_obj = pickle.load( open(\"data/ukiobj-\" + str(5) + \".dat\", \"rb\" ) )\n",
    "\n",
    "trained_net = create_net(ind, outd, layers, width, activation, initializer, outputlayer, uki_obj.theta_mean[-1])\n",
    "\n",
    "print(trained_net.modus['LinM{}'.format(1)].weight)\n",
    "print(trained_net.modus['LinM{}'.format(1)].bias)\n",
    "print(trained_net.modus['LinMout'].weight)\n",
    "print(trained_net.modus['LinMout'].bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/central/home/dzhuang/Code/Point-Jet/Point_jet/Solver.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mu = net(torch.tensor(x, dtype=torch.float32)).detach().numpy().flatten() * mu_scale\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.from_numpy(np.stack((np.fabs(q_mean.flatten()), dq_dx_mean.flatten())).T.astype(np.float32)) \n",
    "y_pred = net_eval(x_train, trained_net).reshape((N_data, Nx))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=True, figsize=(16,12))\n",
    "for i in range(N_data):\n",
    "    ax[0].plot(closure_mean[i,:], xx[i,:], color=\"C\"+str(i))\n",
    "    ax[0].plot(y_pred[i,:]*dq_dx_mean[i,:], xx[i,:], \"--\", color=\"C\"+str(i))\n",
    "    \n",
    "    ax[1].plot(mu_f[i,:], xx[i,:], color=\"C\"+str(i))\n",
    "    ax[1].plot(y_pred[i,:], xx[i,:], \"--\", color=\"C\"+str(i))\n",
    "    \n",
    "    ax[0].set_xlabel(\"closure\")\n",
    "    ax[1].set_xlabel(\"mu\")\n",
    "\n",
    "fig.savefig(\"Point-Jet-Direct-Test.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plug-in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_jet(tau_inv, trained_net):\n",
    "\n",
    "    beta = 1.0\n",
    "    Nx = 384\n",
    "    omega_jet = np.zeros(Nx)\n",
    "    omega_jet[0:Nx//2] = 1.0\n",
    "    omega_jet[Nx//2:Nx] = -1.0\n",
    "    L = 4*np.pi\n",
    "    yy = np.linspace(-L/2.0, L/2.0, Nx)\n",
    "    q_jet = omega_jet + beta*yy\n",
    "\n",
    "\n",
    "\n",
    "    tau = 1/float(tau_inv)\n",
    "    data_dir = \"../data/beta_1.0_Gamma_1.0_relax_\" + tau_inv + \"/\"\n",
    "    dq_dy = scipy.io.loadmat(data_dir+\"data_dq_dy.mat\")[\"data_dq_dy\"]\n",
    "    closure = scipy.io.loadmat(data_dir+\"data_closure_cons.mat\")[\"data_closure_cons\"]\n",
    "    w = scipy.io.loadmat(data_dir+\"data_w.mat\")[\"data_w\"]\n",
    "    q = scipy.io.loadmat(data_dir+\"data_q.mat\")[\"data_q\"]\n",
    "\n",
    "    _, Ny, Nt = q.shape\n",
    "    q_mean_ref = np.mean(q[0, :, Nt//2:], axis=1)\n",
    "    w_mean_ref = np.mean(w[0, :, Nt//2:], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    nn_model = partial(nn_flux, net=trained_net, non_negative=True)\n",
    "    model = lambda q, yy, res : nummodel_flux(nn_model, q, yy, res)\n",
    "    dt, Nt, save_every = 1.0e-4, 200000, 1000\n",
    "    yy, t_pred, q_pred = explicit_solve(model, q_jet, tau, dt, Nt, save_every, L = L)\n",
    "    q_mean_pred = np.mean(q_pred[Nt//(2*save_every):, :], axis=0)\n",
    "    \n",
    "    \n",
    "    return yy, q_mean_ref, q_mean_pred\n",
    "\n",
    "yy, q_mean_ref, q_mean_pred = point_jet( \"0.08\" , trained_net)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=True, figsize=(8,6))\n",
    "\n",
    "\n",
    "ax[0].plot(q_mean_ref, yy,   label=\"ref\")                                                                         \n",
    "ax[0].plot(q_mean_pred, yy, label=\"plug-in\")\n",
    "ax[1].plot(q_mean_ref  - beta*yy, yy,   label=\"ref\")                                                                         \n",
    "ax[1].plot(q_mean_pred - beta*yy, yy, label=\"plug-in\")\n",
    "ax[0].set_xlabel(\"q\")\n",
    "ax[1].set_xlabel(\"omega\")\n",
    "                                                                                                            \n",
    "plt.legend()\n",
    "fig.savefig(\"Point-Jet-Indirect-Test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
