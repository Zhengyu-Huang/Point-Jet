{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from timeit import default_timer\n",
    "from Solver import *\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append('../Utility')\n",
    "from Numerics import gradient_first,  gradient_first_c2f, gradient_first_f2c, interpolate_c2f, interpolate_f2c, psi_fft_sol, gradient_fft\n",
    "import NeuralNet\n",
    "import PlotDefault\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  0  Epoch time :  0.15994891477748752  Train L2 Loss :  4049017.8393554688\n",
      "Epoch :  100  Epoch time :  0.100262519903481  Train L2 Loss :  862.3997733592987\n",
      "Epoch :  200  Epoch time :  0.09387932764366269  Train L2 Loss :  854.7757195234299\n",
      "Epoch :  300  Epoch time :  0.09599088691174984  Train L2 Loss :  854.1250422000885\n",
      "Epoch :  400  Epoch time :  0.09634441370144486  Train L2 Loss :  864.3645453453064\n",
      "Epoch :  500  Epoch time :  0.09134048502892256  Train L2 Loss :  856.7524404525757\n",
      "Epoch :  600  Epoch time :  0.11628606915473938  Train L2 Loss :  857.8716133832932\n",
      "Epoch :  700  Epoch time :  0.09332923218607903  Train L2 Loss :  857.1931837797165\n",
      "Epoch :  800  Epoch time :  0.09523880109190941  Train L2 Loss :  856.0808984041214\n",
      "Epoch :  900  Epoch time :  0.09304055524989963  Train L2 Loss :  855.1683585643768\n"
     ]
    }
   ],
   "source": [
    "Nx = 10000\n",
    "\n",
    "q_mean   = 5.0*np.random.random(Nx) * q_scale\n",
    "dpv_mean = 5.0*np.random.random(Nx) * dpv_scale\n",
    "psi_mean = 5.0*np.random.random(Nx) * psi_scale\n",
    "\n",
    "mu_mean  = (0.1*np.random.random(Nx) + 1.0) * mu_scale\n",
    "\n",
    "# scale input \n",
    "nn_save_name = \"pretrain.nn\"\n",
    "x_train = torch.from_numpy(np.stack((np.fabs(q_mean).flatten()/q_scale, dpv_mean.flatten()/dpv_scale, np.fabs(psi_mean).flatten()/psi_scale)).T.astype(np.float32)) \n",
    "y_train = torch.from_numpy(mu_mean.flatten()[:,np.newaxis].astype(np.float32)) / mu_scale\n",
    "\n",
    "\n",
    "\n",
    "ind = x_train.shape[1]\n",
    "outd = y_train.shape[1] \n",
    "\n",
    "learning_rate = 0.001\n",
    "step_size = 100\n",
    "gamma = 0.5  \n",
    "epochs = 1000\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "net = NeuralNet.FNN(ind, outd, layers, width, activation, initializer, outputlayer) \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "optimizer = NeuralNet.Adam(net.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "myloss = torch.nn.MSELoss(reduction='sum')\n",
    "t0 = default_timer()\n",
    "for ep in range(epochs):\n",
    "    net.train()\n",
    "    t1 = default_timer()\n",
    "    train_l2 = 0\n",
    "    for x, y in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = net(x)\n",
    "        \n",
    "        loss = myloss(out , y)*100\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_l2 += loss.item()\n",
    "\n",
    "#     scheduler.step()\n",
    "\n",
    "    if ep % 100 == 0:\n",
    "        # train_l2/= ntrain\n",
    "        t2 = default_timer()\n",
    "        print(\"Epoch : \", ep, \" Epoch time : \", t2-t1, \" Train L2 Loss : \", train_l2)\n",
    "        if nn_save_name is not None:\n",
    "            torch.save(net, nn_save_name)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 4.3011e-05,  3.5696e-04, -1.3163e-03]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.0479], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(trained_net.modus['LinM{}'.format(1)].weight)\n",
    "# print(trained_net.modus['LinM{}'.format(1)].bias)\n",
    "print(net.modus['LinMout'].weight)\n",
    "print(net.modus['LinMout'].bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
